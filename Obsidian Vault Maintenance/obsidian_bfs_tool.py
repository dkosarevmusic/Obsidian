import os
import re
import collections
import shutil
from pathlib import Path
from datetime import datetime
from urllib.parse import unquote, quote as url_quote

# ================== CONFIGURATION ==================
# –£–∫–∞–∂–∏—Ç–µ –ê–ë–°–û–õ–Æ–¢–ù–´–ô –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É Obsidian
# –ü—Ä–∏–º–µ—Ä –¥–ª—è Windows: "C:/Users/User/Documents/MyVault"
# –ü—Ä–∏–º–µ—Ä –¥–ª—è macOS/Linux: "/home/user/MyVault". –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å / –≤–º–µ—Å—Ç–æ \.
VAULT_PATH = "C:\Obsidian\dkosarevmusic"

# –ò–º—è —Ñ–∞–π–ª–∞ (—Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .md), —Å –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—á–Ω–µ—Ç—Å—è –ø–æ–∏—Å–∫.
# –°–∫—Ä–∏–ø—Ç –Ω–∞–π–¥–µ—Ç –µ–≥–æ –≤ –ª—é–±–æ–π –ø–æ–¥–ø–∞–ø–∫–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
START_FILE_NAME = "DVFU.md"

RESULTS_FILE_NAME = "BFS_report.md"
# ===================================================

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [text](link.md)
# 2. [text](link.md) or ![embed](link.md)
INLINE_RE = re.compile(r'\[.*?\]\(([^)\s#?]+)')


def build_file_index(vault_path: Path) -> dict[str, Path]:
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫.
    –ö–ª—é—á - –∏–º—è —Ñ–∞–π–ª–∞ (e.g., 'My Note.md'), –∑–Ω–∞—á–µ–Ω–∏–µ - –ø–æ–ª–Ω—ã–π –ø—É—Ç—å (Path object).
    """
    index = {}
    for root, _, files in os.walk(vault_path):
        for file in files:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º normcase –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞ Windows
            index[os.path.normcase(file)] = Path(root) / file
    return index

def find_file_in_vault(file_index: dict[str, Path], file_name: str) -> Path | None:
    """–ò—â–µ—Ç —Ñ–∞–π–ª –≤ –∏–Ω–¥–µ–∫—Å–µ, –ø—Ä–æ–±—É—è —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω–∏."""
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    path = file_index.get(os.path.normcase(file_name))
    if path:
        return path
    # –ï—Å–ª–∏ —É –∏–º–µ–Ω–∏ –Ω–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è, –ø—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å .md
    if not file_name.lower().endswith('.md'):
        path = file_index.get(os.path.normcase(f"{file_name}.md"))
        if path:
            return path
    return None

def _clean_markdown_body(body: str) -> str:
    """
    –†–∞–Ω–µ–µ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —É–¥–∞–ª—è–ª–∞ –±–ª–æ–∫–∏ –∫–æ–¥–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏.
    –°–µ–π—á–∞—Å –æ–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞ —Å—Å—ã–ª–æ–∫,
    —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ø—É—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
    """
    return body

def _parse_links_from_text(text: str, current_dir: Path, file_index: dict[str, Path]) -> set[Path]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∏—Å—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¢–ï–ö–°–¢–ê.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–±–æ—Ä –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –ø—É—Ç–µ–π (Path objects) –∫ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º.
    """
    links = set()
    cleaned_body = _clean_markdown_body(text)

    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ [[...]], –∞ –∑–∞—Ç–µ–º –ø–∞—Ä—Å–∏–º –µ–≥–æ.
    wikilink_re = re.compile(r'\[\[(.*?)\]\]')
    for match in wikilink_re.finditer(cleaned_body):
        full_link_text = match.group(1)

        # –û—Ç–¥–µ–ª—è–µ–º –∞–ª–∏–∞—Å (—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ |)
        link_part = full_link_text.split('|', 1)[0]
        # –û—Ç–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ #) –∏ ID –±–ª–æ–∫–∞ (—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ ^)
        file_part = link_part.split('#', 1)[0].split('^', 1)[0]

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∏—â–µ–º —Ñ–∞–π–ª
        decoded_link = unquote(file_part.strip())
        if not decoded_link:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Å—ã–ª–∫–∏ —Ç–∏–ø–∞ [[|alias]]
            continue

        target_path = find_file_in_vault(file_index, decoded_link)
        if target_path and target_path.exists():
            links.add(target_path)

    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ Inline-—Å—Å—ã–ª–æ–∫
    for match in INLINE_RE.finditer(cleaned_body):
        raw_link = match.group(1).strip()
        # current_dir = file_path.parent
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º URL-–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, %20 -> –ø—Ä–æ–±–µ–ª)
        decoded_link = unquote(raw_link)

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑—Ä–µ—à–∏—Ç—å –∫–∞–∫ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
        potential_path = (current_dir / decoded_link).resolve()

        if potential_path.is_file() and potential_path.exists():
            links.add(potential_path)
        else:  # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—â–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –≤–æ –≤—Å–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            file_name_only = Path(decoded_link).name
            target_path = find_file_in_vault(file_index, file_name_only)
            if target_path and target_path.exists():
                links.add(target_path)
                
    return links

def parse_file_links(file_path: Path, file_index: dict[str, Path]) -> dict[str, set[Path]]:
    """
    –ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –∏–∑ –µ–≥–æ frontmatter –∏ —Ç–µ–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –¥–≤—É–º—è –Ω–∞–±–æ—Ä–∞–º–∏ —Å—Å—ã–ª–æ–∫: {'frontmatter': set(), 'body': set()}.
    """
    results = {'frontmatter': set(), 'body': set()}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except (IOError, UnicodeDecodeError):
        return results

    frontmatter = ""
    body = ""
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) > 1:
            frontmatter = parts[1]
        if len(parts) > 2:
            body = parts[2]
    else:
        body = content

    if frontmatter:
        results['frontmatter'] = _parse_links_from_text(frontmatter, file_path.parent, file_index)
    if body:
        results['body'] = _parse_links_from_text(body, file_path.parent, file_index)
        
    return results

def build_link_maps(vault_path: Path, file_index: dict[str, Path]) -> tuple[dict, dict]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–≤—É—Ö –∫–∞—Ä—Ç:
    1. forward_graph: {source_file: {'body': {links}, 'frontmatter': {links}}}
    2. backlinks_map (—Ç–æ–ª—å–∫–æ –¥–ª—è frontmatter): {target_file: {sources}}
    """
    print("üîÑ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã —Å—Å—ã–ª–æ–∫...")
    forward_graph = {}
    backlinks_map = collections.defaultdict(set)
    all_md_files = list(vault_path.rglob('*.md'))
    
    for i, source_path in enumerate(all_md_files):
        if (i + 1) % 500 == 0 or i + 1 == len(all_md_files):
            print(f"  - –ü—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {i+1}/{len(all_md_files)} —Ñ–∞–π–ª–æ–≤...")
        
        all_links = parse_file_links(source_path, file_index)
        forward_graph[source_path.resolve()] = all_links
        
        for target_path in all_links.get('frontmatter', set()):
            backlinks_map[target_path.resolve()].add(source_path.resolve())
    print(f"‚úÖ –ö–∞—Ä—Ç–∞ —Å—Å—ã–ª–æ–∫ —Å–æ–∑–¥–∞–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(forward_graph)} —Ñ–∞–π–ª–æ–≤.")
    return forward_graph, backlinks_map

def perform_bfs(start_file_path: Path, vault: Path, forward_graph: dict, backlinks_map: dict) -> tuple[dict, list]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–±—Ö–æ–¥ –≤ —à–∏—Ä–∏–Ω—É (BFS) –æ—Ç —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –ø–æ—Å–µ—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (path -> level) –∏ —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫.
    """
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ö–æ–¥ –≤ —à–∏—Ä–∏–Ω—É (BFS) –æ—Ç '{start_file_path.name}'...")
    queue = collections.deque([(start_file_path, 0, None)]) # path, level, parent_path
    visited = {}  # path -> {'level': level, 'parent': parent_path}
    errors = []
    
    while queue:
        current_path, level, parent_path = queue.popleft()
        current_path = current_path.resolve()
        if current_path in visited:
            continue
        
        visited[current_path] = {'level': level, 'parent': parent_path}
        print(f"  - –û–±—Ä–∞–±–æ—Ç–∫–∞ ({len(visited)}): {current_path.relative_to(vault)}")

        # 1. –ò—â–µ–º –ò–°–•–û–î–Ø–©–ò–ï —Å—Å—ã–ª–∫–∏ –∏–∑ –¢–ï–õ–ê (–∏–∑ –ø—Ä–µ–¥-–ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã)
        file_links = forward_graph.get(current_path.resolve(), {})
        out_links_from_body = file_links.get("body", set())
        for link in out_links_from_body:
            if link.resolve() not in visited:
                queue.append((link, level + 1, current_path))
        
        # 2. –ò—â–µ–º –í–•–û–î–Ø–©–ò–ï —Å—Å—ã–ª–∫–∏ –∏–∑ FRONTMATTER'–∞ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
        in_links_from_frontmatter = backlinks_map.get(current_path.resolve(), set())
        for link_source in in_links_from_frontmatter:
            if link_source.resolve() not in visited:
                queue.append((link_source, level + 1, current_path))

    print(f"\n‚úÖ –û–±—Ö–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(visited)} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.")
    return visited, errors


def _create_obsidian_link(file_path: Path, vault: Path) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—É—é wikilink-—Å—Å—ã–ª–∫—É –¥–ª—è Obsidian."""
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—ã–µ —Å–ª—ç—à–∏
    relative_path_str = file_path.relative_to(vault).as_posix()
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .md –¥–ª—è markdown-—Ñ–∞–π–ª–æ–≤
    if relative_path_str.lower().endswith('.md'):
        link_text = relative_path_str[:-3]
    else:
        link_text = relative_path_str
        
    return f"[[{link_text}]]"


def generate_report_body(levels: dict, vault: Path) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–ª–æ –æ—Ç—á–µ—Ç–∞ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º —Ñ–∞–π–ª–æ–≤."""
    report_lines = []
    report_lines.append("## üìÇ –§–∞–π–ª—ã –ø–æ —É—Ä–æ–≤–Ω—è–º (—Å—Å—ã–ª–∫–∏ –¥–ª—è Obsidian)\n\n")
    report_lines.append("–§–∞–π–ª—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞ –Ω–∏—Ö —Å—Å—ã–ª–∞—é—Ç—Å—è.\n\n")

    for level in sorted(levels.keys()):
        report_lines.append(f"### –£—Ä–æ–≤–µ–Ω—å {level}\n")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
        # None (–¥–ª—è —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞) –¥–æ–ª–∂–µ–Ω –∏–¥—Ç–∏ –ø–µ—Ä–≤—ã–º
        parents_at_level = sorted(levels[level].keys(), key=lambda p: (p is None, str(p)), reverse=True)
        for parent_path in parents_at_level:
            child_paths = sorted(levels[level][parent_path])

            if parent_path is None:
                # –≠—Ç–æ —Å—Ç–∞—Ä—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–∞ —É—Ä–æ–≤–Ω–µ 0
                for file_path in child_paths:
                    report_lines.append(f"- **–°—Ç–∞—Ä—Ç–æ–≤—ã–π —Ñ–∞–π–ª:** {_create_obsidian_link(file_path, vault)}\n")
            else:
                # –§–∞–π–ª—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è
                report_lines.append(f"- –°–≤—è–∑–∞–Ω—ã –∏–∑ **{_create_obsidian_link(parent_path, vault)}**:\n")
                for file_path in child_paths:
                    report_lines.append(f"  - {_create_obsidian_link(file_path, vault)}\n")
        report_lines.append("\n")
    
    return "".join(report_lines)


def handle_report_mode(f, report_body: str):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ —Ñ–∞–π–ª –æ—Ç—á–µ—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ 'report'."""
    f.write(report_body)


def handle_archive_mode(f, visited: dict, levels: dict, vault: Path, start_file_name: str):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Ä—Ö–∏–≤–∞—Ü–∏—é –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—Ç—á–µ—Ç—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ 'archive'."""
    # --- –ß–∞—Å—Ç—å 1: –ó–∞–ø–∏—Å—å –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ results.md ---
    f.write("## üóÑÔ∏è –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n")

    # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É
    # 1. –û—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞ "Archive" —Ä—è–¥–æ–º —Å —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º
    main_archive_dir = vault.parent / "Archive"

    # 2. –í–Ω—É—Ç—Ä–∏ –Ω–µ–µ - –ø–∞–ø–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Å—Ç–∞—Ä—Ç–æ–≤–æ–º —Ñ–∞–π–ª–µ
    start_file_stem = Path(start_file_name).stem
    run_archive_path = main_archive_dir / f"{start_file_stem} Archive"

    os.makedirs(run_archive_path, exist_ok=True)
    f.write(f"**–§–∞–π–ª—ã –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã –≤:** `{run_archive_path}`\n\n")

    archived_count = 0
    archive_errors = []
    all_files_to_archive = sorted(list(visited.keys()))

    for file_path in all_files_to_archive:
        rel_path = file_path.relative_to(vault)
        rel_path_str = rel_path.as_posix()

        if file_path.name == RESULTS_FILE_NAME:
            f.write(f"- `{rel_path_str}` - ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω (—ç—Ç–æ—Ç —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞)\n")
            continue
        
        destination_path = run_archive_path / rel_path
        os.makedirs(destination_path.parent, exist_ok=True)

        try:
            shutil.move(str(file_path), str(destination_path))
            f.write(f"- `{rel_path_str}` - ‚úÖ –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω\n")
            print(f"  - –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: {rel_path_str}")
            archived_count += 1
        except Exception as e:
            error_msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å {rel_path_str}: {e}"
            archive_errors.append(error_msg)
            f.write(f"- `{rel_path_str}` - ‚ùå –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏\n")
            print(f"  ‚ö†Ô∏è  {error_msg}")
    
    f.write(f"\n**–ò—Ç–æ–≥: –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {archived_count} –∏–∑ {len(all_files_to_archive)} —Ñ–∞–π–ª–æ–≤.**\n\n")
    if archive_errors:
        f.write("### ‚ö†Ô∏è –û—à–∏–±–∫–∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏\n\n")
        for err in archive_errors:
            f.write(f"- `{err}`\n")

    # --- –ß–∞—Å—Ç—å 2: –ó–∞–ø–∏—Å—å –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –ª–æ–≥–∞ –≤ –ø–∞–ø–∫—É –∞—Ä—Ö–∏–≤–∞ ---
    archive_log_path = run_archive_path / "_archive_log.md"
    log_content = []
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ —Å–≤—è–∑—è—Ö
    report_body = generate_report_body(levels, vault)

    log_content.append("---\n")
    log_content.append("tags:\n")
    log_content.append("  - optimization\n")
    log_content.append("  - cleanup\n")
    log_content.append("---\n\n")

    log_content.append(f"# –ê—Ä—Ö–∏–≤ –æ—Ç {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    log_content.append(f"**–û–ø–µ—Ä–∞—Ü–∏—è:** –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ (BFS)\n")
    log_content.append(f"**–°—Ç–∞—Ä—Ç–æ–≤—ã–π —Ñ–∞–π–ª:** `{start_file_name}`\n\n")
    log_content.append(f"**–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∏ –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ:** {len(visited)} —Ñ–∞–π–ª–æ–≤\n\n")
    log_content.append(report_body)

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'w' (write), —Ç–∞–∫ –∫–∞–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–≤–æ–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ª–æ–≥
        with open(archive_log_path, 'w', encoding='utf-8') as log_f:
            log_f.writelines(log_content)
        print(f"‚úÖ –õ–æ–≥ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {archive_log_path}")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏: {e}")


def main(mode: str):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    vault = Path(VAULT_PATH)
    if not vault.is_dir():
        print(f"‚ùå –û—à–∏–±–∫–∞: –£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –∫ —Ö—Ä–∞–Ω–∏–ª–∏—â—É –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: {VAULT_PATH}")
        return

    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Ñ–∞–π–ª–æ–≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
    file_index = build_file_index(vault)
    forward_graph, backlinks_map = build_link_maps(vault, file_index)
    
    start_file_path = find_file_in_vault(file_index, START_FILE_NAME)
    if not start_file_path:
        print(f"‚ùå –û—à–∏–±–∫–∞: –°—Ç–∞—Ä—Ç–æ–≤—ã–π —Ñ–∞–π–ª '{START_FILE_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ '{VAULT_PATH}'.")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ START_FILE_NAME –∏ VAULT_PATH.")
        return

    # 1. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
    visited, errors = perform_bfs(start_file_path, vault, forward_graph, backlinks_map)

    # 2. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ —É—Ä–æ–≤–Ω—è–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ä–æ–¥–∏—Ç–µ–ª—è–º
    levels = collections.defaultdict(lambda: collections.defaultdict(list))
    for path, data in visited.items():
        level = data['level']
        parent = data['parent']
        levels[level][parent].append(path)

    # 3. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞
    results_path = vault / RESULTS_FILE_NAME
    try:
        with open(results_path, 'w', encoding='utf-8') as f:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º YAML frontmatter
            f.write("---\n")
            f.write("tags:\n")
            f.write("  - optimization\n")
            f.write("  - cleanup\n")
            f.write("---\n\n")

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            f.write(f"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ö–æ–¥–∞ –æ—Ç {START_FILE_NAME}\n\n")
            f.write(f"**–†–µ–∂–∏–º:** `{mode}`\n")
            f.write(f"**–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:** {len(visited)}\n\n")

            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
            if mode == 'report':
                report_body = generate_report_body(levels, vault)
                handle_report_mode(f, report_body)
            elif mode == 'archive':
                # –í —Ä–µ–∂–∏–º–µ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏, —Ñ—É–Ω–∫—Ü–∏—è —Å–∞–º–∞ –∑–∞–ø–∏—à–µ—Ç –∏ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –≤ f,
                # –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ –≤ –ø–∞–ø–∫—É –∞—Ä—Ö–∏–≤–∞.
                handle_archive_mode(f, visited, levels, vault, START_FILE_NAME)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏
            if errors:
                f.write("## ‚ö†Ô∏è –û—à–∏–±–∫–∏ –æ–±—Ö–æ–¥–∞\n\n")
                for err in errors:
                    f.write(f"- `{err}`\n")
            elif mode == 'report':
                 f.write("‚úÖ –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ö–æ–¥–µ –Ω–µ –±—ã–ª–æ.\n")

        print(f"\n‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {results_path}")

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

def run_interactive():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ —Å –≤—ã–±–æ—Ä–æ–º –¥–µ–π—Å—Ç–≤–∏—è."""
    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
        print("  1. üìù –°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º)")
        print("  2. üóÑÔ∏è  –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã (–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º, –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ñ–∞–π–ª—ã!)")
        print("  3. üö™ –í—ã—Ö–æ–¥")
        
        choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞ (1-3): ").strip()

        if choice == '1':
            main(mode='report')
            break
        elif choice == '2':
            print("\nüõë –í–ù–ò–ú–ê–ù–ò–ï! –†–µ–∂–∏–º 'archive' –ü–ï–†–ï–ú–ï–°–¢–ò–¢ –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É –∞—Ä—Ö–∏–≤–∞.")
            confirm = input("   –í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (–≤–≤–µ–¥–∏—Ç–µ 'yes' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è): ").strip().lower()
            if confirm == 'yes':
                main(mode='archive')
            else:
                print("–û—Ç–º–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏.")
            break
        elif choice == '3':
            print("–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
            break
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ 1, 2 –∏–ª–∏ 3.")

if __name__ == "__main__":
    run_interactive()
